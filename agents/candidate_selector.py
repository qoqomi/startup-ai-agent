"""
í›„ë³´ ì„ íƒ ì—ì´ì „íŠ¸
ì‚¬ìš©ì queryë¥¼ ê¸°ë°˜ìœ¼ë¡œ íˆ¬ì í‰ê°€í•  ìŠ¤íƒ€íŠ¸ì—… í›„ë³´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
"""

from typing import Dict, List
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
from tavily import TavilyClient
from dotenv import load_dotenv
import os

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class StartupCandidate(BaseModel):
    """ìŠ¤íƒ€íŠ¸ì—… í›„ë³´ ëª¨ë¸"""

    name: str = Field(description="ìŠ¤íƒ€íŠ¸ì—… ì´ë¦„")
    description: str = Field(description="ìŠ¤íƒ€íŠ¸ì—… ì„¤ëª…")
    website: str = Field(description="ì›¹ì‚¬ì´íŠ¸ URL", default="")
    founded_year: str = Field(description="ì„¤ë¦½ ì—°ë„", default="")
    country: str = Field(
        description="ë³¸ì‚¬ ìœ„ì¹˜ êµ­ê°€ (ì˜ˆ: South Korea, USA)", default=""
    )
    category: str = Field(description="ì‚°ì—… ë¶„ì•¼/ì¹´í…Œê³ ë¦¬")
    relevance_score: float = Field(
        description="ê²€ìƒ‰ ì¿¼ë¦¬ì™€ì˜ ê´€ë ¨ì„± ì ìˆ˜ (0-1)", ge=0, le=1
    )
    reasoning: str = Field(description="ì„ íƒ ì´ìœ ")


class CandidateList(BaseModel):
    """í›„ë³´ ë¦¬ìŠ¤íŠ¸ ëª¨ë¸"""

    candidates: List[StartupCandidate] = Field(description="ìŠ¤íƒ€íŠ¸ì—… í›„ë³´ ë¦¬ìŠ¤íŠ¸")
    total_found: int = Field(description="ê²€ìƒ‰ëœ ì´ í›„ë³´ ìˆ˜")
    search_summary: str = Field(description="ê²€ìƒ‰ ìš”ì•½")


def search_startups(query: str, max_results: int = 10) -> List[Dict]:
    """
    Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íƒ€íŠ¸ì—… ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        max_results: ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    if not tavily_api_key:
        print("âš ï¸ TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        # ê°œë°œìš© ë”ë¯¸ ë°ì´í„°
        return [
            {
                "title": f"ìŠ¤íƒ€íŠ¸ì—… ì˜ˆì‹œ {i+1}",
                "url": f"https://example.com/startup{i+1}",
                "content": f"{query}ì™€ ê´€ë ¨ëœ ìŠ¤íƒ€íŠ¸ì—… {i+1}ì…ë‹ˆë‹¤.",
                "score": 0.9 - (i * 0.1),
            }
            for i in range(3)
        ]

    try:
        client = TavilyClient(api_key=tavily_api_key)
        search_result = client.search(
            query=f"{query} í•œêµ­ ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì ìœ ì¹˜ Korea startup funding",
            max_results=max_results,
            search_depth="advanced",
            days=720,
            include_domains=[
                "crunchbase.com",  # ìŠ¤íƒ€íŠ¸ì—… ë°ì´í„°ë² ì´ìŠ¤
                "techcrunch.com",  # í…Œí¬ ë‰´ìŠ¤
                "platum.kr",  # í•œêµ­ ìŠ¤íƒ€íŠ¸ì—… ë‰´ìŠ¤
                "startuptoday.kr",  # í•œêµ­ ìŠ¤íƒ€íŠ¸ì—… íˆ¬ë°ì´
                "venturesquare.net",  # ë²¤ì²˜ìŠ¤í€˜ì–´
                "beSUCCESS.com",  # ë¹„ì„ì„¸ìŠ¤
                "zdnet.co.kr",  # í•œêµ­ IT ë‰´ìŠ¤
                "mk.co.kr",  # ë§¤ì¼ê²½ì œ
                "hankyung.com",  # í•œêµ­ê²½ì œ
                "forbes.com",  # ë¹„ì¦ˆë‹ˆìŠ¤ ë‰´ìŠ¤
            ],
        )
        return search_result.get("results", [])
    except Exception as e:
        print(f"âš ï¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def analyze_candidates(query: str, search_results: List[Dict]) -> CandidateList:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ì í›„ë³´ ì„ íƒ

    Args:
        query: ì‚¬ìš©ì ê²€ìƒ‰ ì¿¼ë¦¬
        search_results: ì›¹ ê²€ìƒ‰ ê²°ê³¼

    Returns:
        ì„ íƒëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸
    """
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    parser = JsonOutputParser(pydantic_object=CandidateList)

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ë‹¹ì‹ ì€ ë²¤ì²˜ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ì ê°€ì¹˜ê°€ ìˆëŠ” ìŠ¤íƒ€íŠ¸ì—… í›„ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš”.

ğŸš¨ **í•„ìˆ˜ ì¡°ê±´**:
1. **ë°˜ë“œì‹œ í•œêµ­(South Korea)ì— ë³¸ì‚¬ë¥¼ ë‘” ìŠ¤íƒ€íŠ¸ì—…ë§Œ ì„ íƒ**
2. **ì •í™•íˆ 1ê°œë§Œ ì„ íƒ** (ê°€ì¥ íˆ¬ì ê°€ì¹˜ê°€ ë†’ì€ í›„ë³´)
3. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ "South Korea", "Seoul", "í•œêµ­", "ëŒ€í•œë¯¼êµ­" ë“±ì˜ í‚¤ì›Œë“œ í™•ì¸
4. country í•„ë“œì— ë°˜ë“œì‹œ êµ­ê°€ ì •ë³´ ê¸°ì…
5. ì„ íƒ ì´ìœ ì™€ ì„¤ëª…ì— ëŒ€í•´ì„œëŠ” í•œêµ­ë§ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ì„ íƒ ê¸°ì¤€:
1. **í•œêµ­ ê¸°ì—… í•„ìˆ˜**: í•œêµ­ì— ë³¸ì‚¬ë¥¼ ë‘” ìŠ¤íƒ€íŠ¸ì—…ë§Œ ì„ íƒ (ì™¸êµ­ ê¸°ì—… ì œì™¸)
2. í˜ì‹ ì„±: ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸
3. ì‹œì¥ì„±: ëª…í™•í•œ íƒ€ê²Ÿ ì‹œì¥ê³¼ ì„±ì¥ ê°€ëŠ¥ì„±
4. ì •ë³´ ê°€ìš©ì„±: íˆ¬ì ë¶„ì„ì— í•„ìš”í•œ ì •ë³´ê°€ ì¶©ë¶„í•œì§€
5. íˆ¬ì ê°€ì¹˜: ìµœê³ ì˜ íˆ¬ì í›„ë³´ 1ê°œ ì„ ì •


**ì •í™•íˆ 1ê°œì˜ í•œêµ­ ìŠ¤íƒ€íŠ¸ì—…**ì„ ì„ íƒí•˜ì„¸ìš”.
ì´í›„ ê²½ìŸì‚¬ íƒìƒ‰ ë‹¨ê³„ì—ì„œ ë¹„êµ ëŒ€ìƒì„ ì°¾ìŠµë‹ˆë‹¤.

ì˜ˆì‹œ:
- âœ… ì¢‹ì€ ì„ íƒ: 
  * "Rebellions (South Korea, AI Chip)" - ìµœê³  íˆ¬ì ê°€ì¹˜ ë³´ìœ 
  * "Toss (South Korea, Fintech)" - ì‹œì¥ ì„ ë„ ê¸°ì—…
- âŒ ë‚˜ìœ ì„ íƒ:
  * "OpenAI (USA)" â†’ ì™¸êµ­ ê¸°ì—…
  * ì—¬ëŸ¬ ê°œ ì„ íƒ â†’ 1ê°œë§Œ ì„ íƒí•´ì•¼ í•¨

{format_instructions}
""",
            ),
            (
                "user",
                """
ê²€ìƒ‰ ì¿¼ë¦¬: {query}

ê²€ìƒ‰ ê²°ê³¼:
{search_results}

ìœ„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ì í›„ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš”.
""",
            ),
        ]
    )

    chain = prompt | llm | parser

    try:
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§¤íŒ…
        formatted_results = "\n\n".join(
            [
                f"[{i+1}] {r.get('title', 'N/A')}\nURL: {r.get('url', 'N/A')}\n{r.get('content', 'N/A')[:500]}"
                for i, r in enumerate(search_results[:10])
            ]
        )

        result = chain.invoke(
            {
                "query": query,
                "search_results": formatted_results,
                "format_instructions": parser.get_format_instructions(),
            }
        )

        return CandidateList(**result)

    except Exception as e:
        print(f"âš ï¸ í›„ë³´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # í´ë°±: ê¸°ë³¸ í›„ë³´ ë°˜í™˜
        return CandidateList(
            candidates=[
                StartupCandidate(
                    name=f"í›„ë³´ {i+1}",
                    description=r.get("content", "")[:200],
                    website=r.get("url", ""),
                    category="Unknown",
                    relevance_score=r.get("score", 0.5),
                    reasoning="ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ìë™ ì„ íƒ",
                )
                for i, r in enumerate(search_results[:3])
            ],
            total_found=len(search_results),
            search_summary=f"{query}ì— ëŒ€í•œ ê²€ìƒ‰ ì™„ë£Œ",
        )


def run(state: Dict) -> Dict:
    """
    í›„ë³´ ì„ íƒ ì—ì´ì „íŠ¸ ì‹¤í–‰

    Args:
        state: AgentState (query í¬í•¨)

    Returns:
        ì—…ë°ì´íŠ¸ëœ state (candidates í¬í•¨)
    """
    query = state.get("query", "")
    print(f"\nğŸ” í›„ë³´ ì„ íƒ ì‹œì‘: {query}")

    # 1. ì›¹ ê²€ìƒ‰
    print("ğŸ“¡ ì›¹ ê²€ìƒ‰ ì¤‘...")
    search_results = search_startups(query, max_results=10)
    print(f"âœ… {len(search_results)}ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ ë°œê²¬")

    # 2. AI ë¶„ì„ìœ¼ë¡œ í›„ë³´ ì„ íƒ
    print("ğŸ¤– AI ë¶„ì„ ì¤‘...")
    candidate_analysis = analyze_candidates(query, search_results)
    print(f"âœ… {len(candidate_analysis.candidates)}ê°œì˜ í›„ë³´ ì„ íƒë¨")

    # 3. State ì—…ë°ì´íŠ¸
    candidates = [
        {
            "name": c.name,
            "description": c.description,
            "website": c.website,
            "founded_year": c.founded_year,
            "country": c.country,
            "category": c.category,
            "relevance_score": c.relevance_score,
            "reasoning": c.reasoning,
        }
        for c in candidate_analysis.candidates
    ]

    print("\nâœ… ì„ íƒëœ íˆ¬ì í›„ë³´:")
    if len(candidates) > 0:
        c = candidates[0]
        country_flag = (
            "ğŸ‡°ğŸ‡·"
            if "Korea" in c.get("country", "") or "í•œêµ­" in c.get("country", "")
            else "ğŸŒ"
        )
        print(f"  ğŸ¯ {c['name']} {country_flag}")
        print(f"     êµ­ê°€: {c.get('country', 'Unknown')}")
        print(f"     ì‚°ì—…: {c.get('category', 'Unknown')}")
        print(f"     ê´€ë ¨ì„±: {c.get('relevance_score', 0):.2f}")
        print(f"     ì„¤ëª…: {c['description'][:100]}...")
        print(f"\n  ğŸ’¡ ì„ íƒ ì´ìœ : {c.get('reasoning', 'N/A')}")
        print(f"\n  ğŸ“Š ë‹¤ìŒ ë‹¨ê³„: 1ì°¨ ë¶„ì„ ì™„ë£Œ í›„ ì´ í›„ë³´ì˜ ê²½ìŸì‚¬ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤")

    return {
        **state,
        "candidates": candidates,
        "search_results": search_results,  # ìºì‹±ìš©
    }


# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    test_state = {"query": "AI ë°ì´íŒ… ì„œë¹„ìŠ¤ ìŠ¤íƒ€íŠ¸ì—…"}
    result = run(test_state)
    print("\n=== ê²°ê³¼ ===")
    print(f"í›„ë³´ ìˆ˜: {len(result['candidates'])}")
    for candidate in result["candidates"]:
        print(f"\n{candidate['name']}")
        print(f"  - {candidate['description']}")
        print(f"  - ê´€ë ¨ì„±: {candidate['relevance_score']}")
